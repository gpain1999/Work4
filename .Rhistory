VingtP[c]<-quantile(cote,0.2)
Trente[c]<-quantile(cote,0.3)
Quarante[c]<-quantile(cote,0.4)
Med[c]<-median(cote)
Soixante[c]<-quantile(cote,0.6)
septante[c]<-quantile(cote,0.7)
octante[c]<-quantile(cote,0.8)
nonante[c]<-quantile(cote,0.9)
Supe[c]<-max(cote)
names[c]<-paste(row.names(m1),row.names(m2),row.names(m3))
c<-c+1
rm(list=ls())
setwd("C:/Users/guill/OneDrive/Documents")
donnees <- read.csv2("ParisCroise2.csv", header = TRUE,sep=";",row.names = 1,dec=",")
n<-length(donnees[,1])*(length(donnees[,1])-1)/2
Supe<-rep(NA,n)
Infe<-rep(NA,n)
Dix<-rep(NA,n)
VingtP<-rep(NA,n)
Trente<-rep(NA,n)
Quarante<-rep(NA,n)
Med<-rep(NA,n)
Soixante<-rep(NA,n)
septante<-rep(NA,n)
octante<-rep(NA,n)
nonante<-rep(NA,n)
names<-rep(NA,n)
c<-1
for (i in 1:(length(donnees[,1])-1)){
for (k in (i+1):(length(donnees[,1]))){
m1<-donnees[i,]
m2<-donnees[k,]
cote<-matrix(NA,9)
count<-1
for (m in 1:3){
for (n in 1:3){
cote[count]<-as.numeric(m1[m]*m2[n])
count<-count+1
}
}
Infe[c]<-min(cote)
Dix[c]<-quantile(cote,0.1)
VingtP[c]<-quantile(cote,0.2)
Trente[c]<-quantile(cote,0.3)
Quarante[c]<-quantile(cote,0.4)
Med[c]<-median(cote)
Soixante[c]<-quantile(cote,0.6)
septante[c]<-quantile(cote,0.7)
octante[c]<-quantile(cote,0.8)
nonante[c]<-quantile(cote,0.9)
Supe[c]<-max(cote)
names[c]<-paste(row.names(m1),row.names(m2))
c<-c+1
}
}
DATA<-cbind(Infe,Dix,VingtP,Trente,Quarante,Med,Soixante,septante,octante,nonante,Supe)
row.names(DATA)<-names
View(DATA)
DATA2<-subset(DATA,DATA$Infe>=6)
DATA$Infe
DATA<-cbind(Infe,Dix,VingtP,Trente,Quarante,Med,Soixante,septante,octante,nonante,Supe)
row.names(DATA)<-names
View(DATA)
View(subset(DATA,DATA[,1]>=6))
View(subset(DATA,DATA[,1]>=6&DATA[,6]>=7.4))
View(DATA)
sqrt(6.1)
We can see that here the concentration  has dropped between the two time. (8/10 observations)
install.packages("knitr")
install.packages("knitr")
install.packages("knitr")
install.packages("knitr")
install.packages("knitr")
library(knitr)
library(knitr)
install.packages(knitr)
install.packages('knitr')
install.packages("knitr")
S <- as.matrix(1)
S <- as.matrix(1)
S
sample <- rWishart(10, df = 10, S)
sample
Sigma <- cbind(c(1,0,0,0), c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
rWishart(2, df = 100, Sigma) ### sample of size two
Sigma
set.seed(1234)
sampleWishart <- rWishart(5000, df = 10, S)
sampleChiSq <- rchisq(5000, df = 10)
par(mfrow = c(1,2))
hist(sampleWishart, col = "lightblue", main = expression(paste("Wishart Distribution", sep ="")), xlim = c(0, 40), breaks = 30, freq = F)
lines(density(sampleWishart), col = "red", lwd = 2)
hist(sampleChiSq, col = "lightblue", main = expression(paste(chi^2, "Distribution", sep = "")), xlim = c(0,40), breaks = 30, freq = F)
lines(density(sampleChiSq), col = "red", lwd = 2)
sample2DWishart <- rWishart(100, df = 10, cbind(c(1,1), c(1,3)))
plot(0,0, pch = "", xlim = c(min(sample2DWishart[1,,]), max(sample2DWishart[1,,])), ylim = c(min(sample2DWishart[2,,]), max(sample2DWishart[2,,])),
xlab = "First column vector", ylab = "Second column vector")
for(i in 1:100){
lines(sample2DWishart[1,,i], sample2DWishart[2,,i], col = "red")
points(sample2DWishart[1,1,i], sample2DWishart[2,1,i], pch = 21, bg = "red", cex = 0.8)
}
samples <- NULL
samples <- cbind(samples, rf(n = 1000, df1 = 1, df2 = 1))
samples <- cbind(samples, rf(n = 1000, df1 = 1, df2 = 10))
samples <- cbind(samples, rf(n = 1000, df1 = 10, df2 = 1))
samples <- cbind(samples, rf(n = 1000, df1 = 100, df2 = 1))
samples <- cbind(samples, rf(n = 1000, df1 = 1000, df2 = 1))
samples <- cbind(samples, rf(n = 1000, df1 = 1000, df2 = 10))
samples <- cbind(samples, rf(n = 1000, df1 = 1000, df2 = 100))
samples <- cbind(samples, rf(n = 1000, df1 = 1000, df2 = 1000))
par(mfrow = c(4,2))
for (i in 1:dim(samples)[2]){
hist(samples[,i], xlab=paste("Sample no.", i, sep = ""), col = "yellow", main = "", freq = F, breaks = 50)
lines(density(samples[,i]), col = "red")
}
library(DescTools)
install.packages("DescTools")
library(DescTools)
library(mvtnorm)
s=matrix(c(1,-0.5,-0.5,1),2);x=seq(-3,3,by=0.015) ### variance-covariance matrix
contour(x,x,outer(x,x, function(x,y){dmvnorm(cbind(x,y),sigma=s)}))
n <- 20
X <- rmvnorm(n,sigma=s)
m <- apply(X,2,mean)
S <- cov(X)
points(m[1],m[2],pch=8,col="red",cex=2)
S1=solve(S)
contour(x,x,outer(x,x,function(x,y){(n-2)*
apply(t(t(cbind(x,y))-m),1,function(x){t(x)%*%S1%*%x})<
2*qf(0.95,2,n-2)}),col="red",add=TRUE)
bodyx=m[1]+c(-1,1)*sqrt(S[1,1]*2*qf (0.95,2,n-2) /(n-2))
bodyy=m[2]+c(-1,1)*sqrt(S[2,2]*2*qf (0.95,2,n-2) /(n-2))
polygon(x=bodyx[c(1,1,2,2,1)],y=bodyy[c(1,2,2,1,1)],border="blue")
round(2/3 * 70.40,2)
70.40-24
4459/25.5
4459/25.55
380*2 + 200
960 /4
taux <- 25.61
taux/37
37/taux
11*90
#install.packages(pkgs="http://www.karlin.mff.cuni.cz/~hlavka/sms2/MSES_1.1.tar.gz",repos=NULL,type="source")
#install.packages(pkgs="http://www.karlin.mff.cuni.cz/~hlavka/sms2/MSES_1.1.zip",repos=NULL)
library(SMSdata)
install.packages(pkgs="http://www.karlin.mff.cuni.cz/~hlavka/sms2/MSES_1.1.tar.gz",repos=NULL,type="source")
#install.packages(pkgs="http://www.karlin.mff.cuni.cz/~hlavka/sms2/MSES_1.1.zip",repos=NULL)
library(SMSdata)
install.packages(pkgs="http://www.karlin.mff.cuni.cz/~hlavka/sms2/MSES_1.1.tar.gz",repos=NULL,type="source")
install.packages(pkgs="http://www.karlin.mff.cuni.cz/~hlavka/sms2/MSES_1.1.zip",repos=NULL)
library(SMSdata)
X1<-rnorm(1000,0,1)
X1<-rnorm(1000,0,1)
X1<-rnorm(10000,0,1)
plot(density(exp(X1)))
plot(density(exp(X1)))
x<-seq(0,20,by=0.01)
x
(1/sqrt(2*pi))
pi
y<-(1/sqrt(2*pi)) * exp((-0.5)*log(x)^2)
plot(x,y)
plot(x,y,type = "l")
plot(density(exp(X1)))
X1<-rnorm(100000,0,1)
plot(density(exp(X1)))
plot(x,y,type = "l")
x<-seq(0,20,by=0.01)
y<-(1/sqrt(2*pi)) * exp((-0.5)*(log(x))^2)
plot(x,y,type = "l")
plot(density(exp(X1)))
plot(x,y,type = "l")
hist(exp(X1))
plot(density(exp(X1)))
plot(density(X1))
plot(density(exp(X1)))
y1<-(1/sqrt(2*pi)) * exp((-0.5)*(x)^2)
x<-seq(0,20,by=0.01)
y1<-(1/sqrt(2*pi)) * exp((-0.5)*(x)^2)
plot(x,y1,type = "l")
plot(density(X1))
plot(x,y1,type = "l")
plot(x,y,type = "l")
max(y)
which(max(y)==y)
x[101]
(1/sqrt(2*pi))
exp(0)
ln(1)
log(1)
X1<-rnorm(100000,0,1)
plot(density(X1))
plot(density(exp(X1)))
max(density(exp(X1)))
density(exp(X1))
density(exp(X1))[[1]]
density(exp(X1))[[2]]
max(density(exp(X1))[[2]])
which(max(density(exp(X1))[[2]])==density(exp(X1))[[2]])
density(exp(X1))[[1]]
density(exp(X1))[[1]][6]
x<-seq(0,20,by=0.01)
plot(x,y,type = "l")
y<-(1/sqrt(2*pi)) * exp((-0.5)*(log(x))^2)/x
plot(x,y,type = "l")
plot(x,y,type = "l")
"2022-03-23"
"2022-03-23"-"2022-01-06"
76/455
X<-runif(100000,0,1)
Y<-runif(100000,0,1)
Z<-X-Y
plot(density(Z))
library("mvtnorm")
n <- 100
mu <-  c(1, 2)
Sigma <- matrix(c(1, 0.5, 0.5, 2),2,2)
set.seed(1234)
sample <- rmvnorm(n, mu, Sigma)
sample
a <- 0
A <- c(2, -1)
Tvalue <- n * t(A %*% apply(sample, 2, mean) - a) %*% solve(A %*% Sigma %*% A) %*% (A %*% apply(sample, 2, mean) - a)
a <- 0
A <- c(2, -1)
Tvalue <- n * t(A %*% apply(sample, 2, mean) - a) %*% solve(A %*% Sigma %*% A) %*% (A %*% apply(sample, 2, mean) - a)
Tvalue
TTvalue <- (n - 1) * t(A %*% apply(sample, 2, mean) - a) %*% solve(A %*% cov(sample) %*% A) %*% (A %*% apply(sample, 2, mean) - a)
TTvalue
qchisq(0.95,1)
qf(0.95,1,99)
library("mvtnorm")
n <- 142
mu <-  c(3, -1)
Sigma <- matrix(c(2, 0.75, 0.75, 1),2,2)
set.seed(1999)
sample <- rmvnorm(n, mu, Sigma)
sample
a <- 0
a <- 0
A <- c(0,0)
Tvalue <- n * t(A %*% apply(sample, 2, mean) - a) %*% solve(A %*% Sigma %*% A) %*% (A %*% apply(sample, 2, mean) - a)
a <- 0
A <- c(1,2)
Tvalue <- n * t(A %*% apply(sample, 2, mean) - a) %*% solve(A %*% Sigma %*% A) %*% (A %*% apply(sample, 2, mean) - a)
qchisq(0.95,1)
Tvalue
a <- 0
A <- c(3,-1)
Tvalue <- n * t(A %*% apply(sample, 2, mean) - a) %*% solve(A %*% Sigma %*% A) %*% (A %*% apply(sample, 2, mean) - a)
qchisq(0.95,1)
Tvalue
a <- 0
A <- c(1,-3)
Tvalue <- n * t(A %*% apply(sample, 2, mean) - a) %*% solve(A %*% Sigma %*% A) %*% (A %*% apply(sample, 2, mean) - a)
qchisq(0.95,1)
Tvalue
a <- 0
A <- c(1,3)
Tvalue <- n * t(A %*% apply(sample, 2, mean) - a) %*% solve(A %*% Sigma %*% A) %*% (A %*% apply(sample, 2, mean) - a)
qchisq(0.95,1)
Tvalue
TTvalue <- (n - 1) * t(A %*% apply(sample, 2, mean) - a) %*% solve(A %*% cov(sample) %*% A) %*% (A %*% apply(sample, 2, mean) - a)
qf(0.95,1,99)
TTvalue
pi^2/6
40*3
45*3
20+75+120+120+25
400*6
2400/60
120/5
120/6
dchisq(Tvalue,1)
p_value_1 <- dchisq(Tvalue,1)
p_value_2 <- df(TTvalue,1,99)
p_value_2
Tvalue
qchisq(0.95,1)
library("mvtnorm")
n <- 1000
mu <-  c(3, -1)
Sigma <- matrix(c(2, 0.75, 0.75, 1),2,2)
set.seed(1999)
sample <- rmvnorm(n, mu, Sigma)
head(sample)
a <- 0
A <- c(1,1)
Tvalue <- n * t(A %*% apply(sample, 2, mean) - a) %*% solve(A %*% Sigma %*% A) %*% (A %*% apply(sample, 2, mean) - a)
Tvalue
qchisq(0.95,1)
p_value_1 <- dchisq(Tvalue,1)
p_value_1
a <- 0
A <- c(1,-3)
Tvalue <- n * t(A %*% apply(sample, 2, mean) - a) %*% solve(A %*% Sigma %*% A) %*% (A %*% apply(sample, 2, mean) - a)
Tvalue
qchisq(0.95,1)
p_value_1 <- dchisq(Tvalue,1)
p_value_1
Tvalue
qchisq(0.95,1)
qchisq(0.95,1)
Tvalue
library("mvtnorm")
n <- 1000
mu <-  c(3, -1)
Sigma <- matrix(c(2, 0.75, 0.75, 1),2,2)
set.seed(1999)
sample <- rmvnorm(n, mu, Sigma)
head(sample)
a <- 0
A <- c(1,-3)
Tvalue <- n * t(A %*% apply(sample, 2, mean) - a) %*% solve(A %*% Sigma %*% A) %*% (A %*% apply(sample, 2, mean) - a)
Tvalue
qchisq(0.95,1)
p_value_1 <- dchisq(Tvalue,1)
p_value_1
a <- 0
A <- c(1,1)
Tvalue <- n * t(A %*% apply(sample, 2, mean) - a) %*% solve(A %*% Sigma %*% A) %*% (A %*% apply(sample, 2, mean) - a)
Tvalue
qchisq(0.95,1)
p_value_1 <- dchisq(Tvalue,1)
p_value_1
TTvalue <- (n - 1) * t(A %*% apply(sample, 2, mean) - a) %*% solve(A %*% cov(sample) %*% A) %*% (A %*% apply(sample, 2, mean) - a)
TTvalue
qf(0.95,1,99)
p_value_2 <- df(TTvalue,1,99)
p_value_2
install.packages(c("broom.helpers", "GGally"))
library(GGally)
library("colorspace")
library("xtable")
library(MASS)
library(questionr)
library(nnet)
library(broom.helpers)
#
setwd("C:/Users/guill/OneDrive/Documents/Charles_University/Advanced Regression Models/Work4")
print(load("AdvRegr_4_nels.RData"))
#repartition %
round(prop.table(with(nels, table(fa.educ, useNA = "ifany")))*100,2)
### Contingency table
(tab1 <- with(nels, table(ses, fa.educ)))
(ptab1 <- round(prop.table(tab1, margin = 2) * 100, 1))
### Data frame for loglinear modelling
(qq1 <- as.data.frame(tab1, responseName = "N"))
#repartition %
round(prop.table(with(nels, table(region, useNA = "ifany")))*100,2)
### Contingency table
(tab2 <- with(nels, table(ses, fa.educ,region)))
(ptab2 <- round(prop.table(tab2, margin = 2) * 100, 1))
### Data frame for loglinear modelling
(qq2 <- as.data.frame(tab2, responseName = "N"))
fitp2.1 <- glm(N ~ (ses*fa.educ)+(ses*region)+(fa.educ*region), family = poisson, data = qq2)
summary(fitp2.1)
regm <- multinom(ses ~ fa.educ +region ,family=poisson, data = nels)
summary(regm)
odds.ratio(regm)
library(GGally)
ggcoef_multinom(
regm,
exponentiate = TRUE
)
ggcoef_multinom(
regm,
type = "faceted",
exponentiate = TRUE
)
library(ggeffects)
install.packages("ggeffects")
library(ggeffects)
plot(ggeffect(regm, "ses"))
plot(ggeffect(regm, "region"))
### Contingency table
(tab2 <- with(nels, table(ses, fa.educ,region,fa.wrk)))
(ptab2 <- round(prop.table(tab2, margin = 2) * 100, 1))
regm3 <- multinom(ses ~ fa.educ +region+fa.wrk ,family=poisson, data = nels)
summary(regm3)
odds.ratio(regm3)
ggcoef_multinom(
regm3,
exponentiate = TRUE
)
plot(ggeffect(regm3, "region"))
fit1 <- glm(N ~ ses + fa.educ + ses:fa.educ, family = poisson, data = qq1)
fitp2.1 <- glm(N ~ ses + fa.educ + region, family = poisson, data = qq2)
fitp2.2 <- glm(N ~ (ses:fa.educ)+(ses:region)+(fa.educ:region), family = poisson, data = qq2)
summary(fitp2.1)
summary(fitp2.2)
fitp2.3 <- glm(N ~ (ses:fa.educ:region), family = poisson, data = qq2)
summary(fitp2.3)
120-96
24/4
#
library("colorspace")
library("xtable")
library(MASS)
library(questionr)
library(nnet)
library(broom.helpers)
print(load("AdvRegr_4_nels.RData"))
#repartition %
round(prop.table(with(nels, table(fa.educ, useNA = "ifany")))*100,2)
### Contingency table
(tab1 <- with(nels, table(ses, fa.educ)))
(ptab1 <- round(prop.table(tab1, margin = 2) * 100, 1))
### Data frame for loglinear modelling
(qq1 <- as.data.frame(tab1, responseName = "N"))
View(qq1)
fit1 <- glm(N ~ ses + fa.educ + ses:fa.educ, family = poisson, data = qq1)
summary(fit1)
View(qq1)
###intro###
rm(list=ls())
#
library("colorspace")
library("xtable")
library(MASS)
library(questionr)
library(nnet)
library(broom.helpers)
#
setwd("C:/Users/guill/OneDrive/Documents/Charles_University/Advanced Regression Models/Work4")
print(load("AdvRegr_4_nels.RData"))
#repartition %
round(prop.table(with(nels, table(fa.educ, useNA = "ifany")))*100,2)
### Contingency table
(tab1 <- with(nels, table(ses, fa.educ)))
print(load("AdvRegr_4_nels.RData"))
#repartition %
round(prop.table(with(nels, table(fa.educ, useNA = "ifany")))*100,2)
### Contingency table
(tab1 <- with(nels, table(ses, fa.educ)))
(ptab1 <- round(prop.table(tab1, margin = 2) * 100, 1))
### Data frame for loglinear modelling
(qq1 <- as.data.frame(tab1, responseName = "N"))
fit1 <- glm(N ~ ses + fa.educ + ses:fa.educ, family = poisson, data = qq1)
summary(fit1)
fit1_bis = glm(N~fa.educ + ses:fa.educ, family = poisson, data = qq1)
summary(fit1_bis)
fit2_bis = glm(N~fa.educ , family = poisson, data = qq1)
summary(fit2_bis)
fit3_bis = glm(N~ses + ses:fa.educ, family = poisson, data = qq1)
summary(fit3_bis)
fit4_bis = glm(N~ses , family = poisson, data = qq1)
summary(fit4_bis)
#
library("colorspace")
library("xtable")
#
print(load("AdvRegr_4_nels.RData"))
### Marginal frequencies
with(nels, table(ses,     useNA = "ifany"))
with(nels, table(sesmed,  useNA = "ifany"))
with(nels, table(parents, useNA = "ifany"))
with(nels, table(foreign, useNA = "ifany"))
with(nels, table(fa.educ, useNA = "ifany"))
with(nels, table(mo.educ, useNA = "ifany"))
with(nels, table(region,  useNA = "ifany"))
with(nels, table(fa.wrk,  useNA = "ifany"))
with(nels, table(mo.wrk,  useNA = "ifany"))
### Contingency table
(xtab1 <- with(nels, table(ses, fa.educ)))
### Exploration: column proportions
prop.table(xtab1, margin = 2)
### Formatted numbers
(ptab1 <- round(prop.table(xtab1, margin = 2) * 100, 1))
### Table in LaTeX
print(xtable(ptab1, digits = c(0, 1, 1, 1)), floating = FALSE)
### Plot (two slightly different versions)
par(mfrow = c(1, 2), mar = c(3, 3, 3, 1) + 0.1)
plot(t(xtab1), col = rainbow_hcl(4), main = "SES by father's education")
plot(ses ~ fa.educ, data = nels, col = rainbow_hcl(4),
main = "SES by father's education")
par(mfrow = c(1, 1))
### Chi^2 test
chisq.test(xtab1)
### Data frame for loglinear modelling
(qq1 <- as.data.frame(xtab1, responseName = "N"))
View(qq1)
### Saturated model
fit1 <- glm(N ~ (ses + fa.educ)^2, family = poisson, data = qq1)
fit5_bis <- glm(N ~ (ses + fa.educ)^2, family = poisson, data = qq1)
summary(fit5_bis)
anova(fit5_bis,fit2_bis)
anova(fit5_bis,fit3_bis)
#repartition %
round(prop.table(with(nels, table(region, useNA = "ifany")))*100,2)
### Contingency table
(tab2 <- with(nels, table(ses, fa.educ,region)))
(ptab2 <- round(prop.table(tab2, margin = 2) * 100, 1))
### Data frame for loglinear modelling
(qq2 <- as.data.frame(tab2, responseName = "N"))
View(qq2)
fitp2.1 <- glm(N ~ ses + fa.educ + region, family = poisson, data = qq2)
fitp2.2 <- glm(N ~ (ses:fa.educ)+(ses:region)+(fa.educ:region), family = poisson, data = qq2)
fitp2.3 <- glm(N ~ (ses:fa.educ:region), family = poisson, data = qq2)
summary(fitp2.1)
summary(fitp2.2)
summary(fitp2.3)
View(qq1)
regm3 <- multinom(ses ~ fa.educ +region+fa.wrk ,family=poisson, data = nels)
summary(regm3)
odds.ratio(regm3)
ggcoef_multinom(
regm3,
exponentiate = TRUE
)
install.packages('GGally')
