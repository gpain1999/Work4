<<<<<<< HEAD
qchisq(0.95,1)
p_value_1 <- dchisq(Tvalue,1)
p_value_1
a <- 0
A <- c(1,-3)
Tvalue <- n * t(A %*% apply(sample, 2, mean) - a) %*% solve(A %*% Sigma %*% A) %*% (A %*% apply(sample, 2, mean) - a)
Tvalue
qchisq(0.95,1)
p_value_1 <- dchisq(Tvalue,1)
p_value_1
Tvalue
qchisq(0.95,1)
qchisq(0.95,1)
Tvalue
library("mvtnorm")
n <- 1000
mu <-  c(3, -1)
Sigma <- matrix(c(2, 0.75, 0.75, 1),2,2)
set.seed(1999)
sample <- rmvnorm(n, mu, Sigma)
head(sample)
a <- 0
A <- c(1,-3)
Tvalue <- n * t(A %*% apply(sample, 2, mean) - a) %*% solve(A %*% Sigma %*% A) %*% (A %*% apply(sample, 2, mean) - a)
Tvalue
qchisq(0.95,1)
p_value_1 <- dchisq(Tvalue,1)
p_value_1
a <- 0
A <- c(1,1)
Tvalue <- n * t(A %*% apply(sample, 2, mean) - a) %*% solve(A %*% Sigma %*% A) %*% (A %*% apply(sample, 2, mean) - a)
Tvalue
qchisq(0.95,1)
p_value_1 <- dchisq(Tvalue,1)
p_value_1
TTvalue <- (n - 1) * t(A %*% apply(sample, 2, mean) - a) %*% solve(A %*% cov(sample) %*% A) %*% (A %*% apply(sample, 2, mean) - a)
TTvalue
qf(0.95,1,99)
p_value_2 <- df(TTvalue,1,99)
p_value_2
install.packages(c("broom.helpers", "GGally"))
library(GGally)
library("colorspace")
library("xtable")
library(MASS)
library(questionr)
library(nnet)
library(broom.helpers)
#
setwd("C:/Users/guill/OneDrive/Documents/Charles_University/Advanced Regression Models/Work4")
print(load("AdvRegr_4_nels.RData"))
#repartition %
round(prop.table(with(nels, table(fa.educ, useNA = "ifany")))*100,2)
### Contingency table
(tab1 <- with(nels, table(ses, fa.educ)))
(ptab1 <- round(prop.table(tab1, margin = 2) * 100, 1))
### Data frame for loglinear modelling
(qq1 <- as.data.frame(tab1, responseName = "N"))
#repartition %
round(prop.table(with(nels, table(region, useNA = "ifany")))*100,2)
### Contingency table
(tab2 <- with(nels, table(ses, fa.educ,region)))
(ptab2 <- round(prop.table(tab2, margin = 2) * 100, 1))
### Data frame for loglinear modelling
(qq2 <- as.data.frame(tab2, responseName = "N"))
fitp2.1 <- glm(N ~ (ses*fa.educ)+(ses*region)+(fa.educ*region), family = poisson, data = qq2)
summary(fitp2.1)
regm <- multinom(ses ~ fa.educ +region ,family=poisson, data = nels)
summary(regm)
odds.ratio(regm)
library(GGally)
ggcoef_multinom(
regm,
exponentiate = TRUE
)
ggcoef_multinom(
regm,
type = "faceted",
exponentiate = TRUE
)
library(ggeffects)
install.packages("ggeffects")
library(ggeffects)
plot(ggeffect(regm, "ses"))
plot(ggeffect(regm, "region"))
### Contingency table
(tab2 <- with(nels, table(ses, fa.educ,region,fa.wrk)))
(ptab2 <- round(prop.table(tab2, margin = 2) * 100, 1))
regm3 <- multinom(ses ~ fa.educ +region+fa.wrk ,family=poisson, data = nels)
summary(regm3)
odds.ratio(regm3)
ggcoef_multinom(
regm3,
exponentiate = TRUE
=======
options(repos = c(
yihui = 'https://yihui.r-universe.dev',
CRAN = 'https://cloud.r-project.org'
))
install.packages('knitr')
library(SMSdata)
#install.packages(pkgs="http://www.karlin.mff.cuni.cz/~hlavka/sms2/MSES_1.1.tar.gz",repos=NULL,type="source")
#install.packages(pkgs="http://www.karlin.mff.cuni.cz/~hlavka/sms2/MSES_1.1.zip",repos=NULL)
library(SMSdata)
download.file("http://www.karlin.mff.cuni.cz/~hlavka/sms2/SMSdata_1.0.zip","SMSdata.zip")
detach("package:SMSdata", unload = TRUE)
library(SMSdata)
download.file("http://www.karlin.mff.cuni.cz/~hlavka/sms2/SMSdata_1.0.zip","SMSdata4.zip")
install.packages("~/Charles_University/Multivariate analysis/Web_site/SMSdata4.zip", repos = NULL, type = "win.binary")
#install.packages(pkgs="http://www.karlin.mff.cuni.cz/~hlavka/sms2/MSES_1.1.tar.gz",repos=NULL,type="source")
#install.packages(pkgs="http://www.karlin.mff.cuni.cz/~hlavka/sms2/MSES_1.1.zip",repos=NULL)
library(SMSdata)
#install.packages(pkgs="http://www.karlin.mff.cuni.cz/~hlavka/sms2/MSES_1.1.tar.gz",repos=NULL,type="source")
install.packages(pkgs="http://www.karlin.mff.cuni.cz/~hlavka/sms2/MSES_1.1.zip",repos=NULL)
library(SMSdata)
install.packages("~/Charles_University/Multivariate analysis/Web_site/SMSdata4.zip", repos = NULL, type = "win.binary")
library(SMSdata)
install.packages("~/Charles_University/Multivariate analysis/Web_site/SMSdata4.zip", repos = NULL, type = "win.binary")
install.packages("~/Charles_University/Multivariate analysis/Web_site/mvadata (1).zip", repos = NULL, type = "win.binary")
download.file("http://www.karlin.mff.cuni.cz/~hlavka/sms2/SMSdata_1.0.zip","SMSdata.zip")
install.packages("~/SMSdata4.zip", repos = NULL, type = "win.binary")
setwd("C:/Users/guill/OneDrive/Documents/Charles_University/Multivariate analysis/Web_site/mvadata")
setwd("C:/Users/guill/OneDrive/Documents/Charles_University/Multivariate analysis/Web_site/mvadata")
setwd("C:/Users/guill/OneDrive/Documents/Charles_University/Multivariate analysis/Web_site")
install.packages("~/Charles_University/Multivariate analysis/Web_site/SMSdata4.zip", repos = NULL, type = "win.binary")
setwd("C:/Users/guill/OneDrive/Documents/Charles_University/Multivariate analysis/Web_site/mvadata")
setwd("C:/Users/guill/OneDrive/Documents/Charles_University/Multivariate analysis/Web_site/mvadata")
my_data <- read.delim("plasma.txt")
my_data <- read.delim("plasma.txt")
library(SMSdata)
my_data <-read.tst("plasma.txt")
setwd("C:/Users/guill/OneDrive/Documents/Charles_University/Multivariate analysis/Web_site/mvadata")
library("readr")
library("readr")
install.packages("Smsdata")
library(SMSdata)
remove.packages("SMSdata", lib="~/R/win-library/4.1")
download.file("http://www.karlin.mff.cuni.cz/~hlavka/sms2/SMSdata_1.0.zip","SMSdata.zip")
download.file("http://www.karlin.mff.cuni.cz/~hlavka/sms2/SMSdata_1.0.zip","SMSdata.zip")
install.packages(pkgs="SMSdata.zip",repos=NULL, type="source")
library(SMSdata)
detach("package:SMSdata", unload = TRUE)
download.file("http://www.karlin.mff.cuni.cz/~hlavka/sms2/SMSdata_1.0.zip","SMSdata14.zip")
install.packages(pkgs="SMSdata14.zip",repos=NULL, type="source")
library(SMSdata)
remove.packages("SMSdata", lib="~/R/win-library/4.1")
download.file("http://www.karlin.mff.cuni.cz/~hlavka/sms2/SMSdata_1.0.zip","SMSdata14.zip")
install.packages(pkgs="SMSdata14.zip",repos=NULL, type="source")
download.file("http://www.karlin.mff.cuni.cz/~hlavka/sms2/SMSdata_1.0.zip","SMSdata.zip")
install.packages(pkgs="SMSdata.zip",repos=NULL, type="source")
library(SMSdata)
install.packages("Hotelling")
download.file("http://www.karlin.mff.cuni.cz/~hlavka/sms2/SMSdata_1.0.zip","SMSdata.zip")
install.packages(pkgs="SMSdata.zip",repos=NULL, type="source")
library(SMSdata)
detach("package:SMSdata", unload = TRUE)
library(SMSdata)
download.file("http://www.karlin.mff.cuni.cz/~hlavka/sms2/SMSdata_1.0.zip","SMSdata.zip")
install.packages(pkgs="SMSdata.zip",repos=NULL, type="source")
my_data <-read.tst("plasma.txt")
my_data <-read.csv2("plasma.csv")
View(my_data)
install.packages("SimDesign")
t.test(my_data$X11am-my_data$X8am)
my_data$X11am-my_data$X8am
summary(t.test(my_data$X11am-my_data$X8am))
t.test(my_data$X11am-my_data$X8am)
test_1<-t.test(my_data$X11am-my_data$X8am)
test_1
test_1<-t.test(my_data$X11am-my_data$X8am)
pvalues<-test_1$p.value
pvalues
test_1<-t.test(my_data$X11am-my_data$X8am)
pvalues<-test_1$p.value
mean(my_data$X11am-my_data$X8am)
pvalues
test_1<-t.test(my_data$X11am-my_data$X8am)
pvalues<-test_1$p.value
mean(my_data$X11am-my_data$X8am)
round(pvalues,3)
test_2<-t.test(my_data$X3pm-my_data$X11am)
pvalues_2<-test_2$p.value
mean(my_data$X3pm-my_data$X11am)
round(pvalues_2,3)
library(plyr)
install.packages("plyr")
install.packages("ggplot2")
library(plyr)
library(ggplot2)
GenderPlot1 = ggplot(my_data, aes(x = group, y = X8am)) + geom_boxplot()
GenderPlot1
my_data <-read.csv2("plasma.csv")
my_data$group<-as.factor(my_data$group)
GenderPlot1_FLIP = ggplot(my_data, aes(x = group, y = X8am)) + geom_boxplot() + coord_flip()
GenderPlot1_FLIP
420/25
16.8/2
t.test(my_data$group, my_data$X8am, alternative = "two.sided", var.equal = FALSE)
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
library("dplyr")
library(dplyr)
group_by(my_data, group) %>%
summarise(
count = n(),
mean = mean(X8am, na.rm = TRUE),
sd = sd(X8am, na.rm = TRUE)
>>>>>>> 3491978b8b8b289a5b4ccd50416c38661c4c805a
)
install.packages("ggpubr")
library("ggpubr")
ggboxplot(my_data, x = "group", y = "X8am",
color = "group", palette = c("#00AFBB", "#E7B800"),
ylab = "X8am", xlab = "Groups")
# Shapiro-Wilk normality test for Men's weights
with(my_data, shapiro.test(X8am[group == "1"]))# p = 0.1
# Shapiro-Wilk normality test for Women's weights
with(my_data, shapiro.test(X8am[group == "2"])) # p = 0.6
res.ftest <- var.test(X8am ~ group, data = my_data)
res.ftest
res <- t.test(X8am ~ group, data = my_data, var.equal = TRUE)
res
25*25
25*50
rnorm(100,0,1)
Data<-cbind(rnorm(100,0,1),rnorm(100,0,1),rnorm(100,0,1),rnorm(100,0,1))
Data
matrix(Data)
dim(matrix(Data))
dim(Data)
matrix(1,2,-3,3)
matrix(c(1,2,-3,3))
dim(matrix(c(1,2,-3,3)))
t(matrix(c(1,2,-3,3)))
Y<-dim(Data) %*% t(matrix(c(1,2,-3,3)))
Y
Y<-Data %*% t(matrix(c(1,2,-3,3)))
Data<-data.frame(cbind(rnorm(100,0,1),rnorm(100,0,1),rnorm(100,0,1),rnorm(100,0,1)))
Y<-Data %*% t(matrix(c(1,2,-3,3)))
matrix(Data)
Data
as.matrix(Data)
Y<-as.matrix(Data) %*% t(matrix(c(1,2,-3,3)))
dim(as.matrix(Data))
t(as.matrix(c(1,2,-3,3)))
Y<-dim(as.matrix(Data)) %*% as.matrix(c(1,2,-3,3))
Y<-as.matrix(Data) %*% as.matrix(c(1,2,-3,3))
Y
dim(Y)
Data<-data.frame(cbind(rnorm(100,0,1),rnorm(100,0,1),rnorm(100,0,1),rnorm(100,0,1)))
Y<-as.matrix(Data) %*% as.matrix(c(1,2,-3,3)) + rnorm(100,0,2)
Data$Y <- Y
View(Data)
res<-glm(Y~.,data=Data)
res
summary(res)
function_glm_sum<-function(glm_object){
return(list(table1,table2))
}
glm_object<-glm(Y~.,data=Data)
glm_object
glm_object$coefficients
dim(glm_object$coefficients)
length(glm_object$coefficients)
table1<-data.frame(matrix(NA,length(glm_object$coefficients)-1,8))
table1
rownames(glm_object$coefficients)
names(glm_object$coefficients)
names(glm_object$coefficients)[2:]
names(glm_object$coefficients)[2:length(glm_object$coefficients)]
rownames(table1)<-names(glm_object$coefficients)[2:length(glm_object$coefficients)]
table1
Data<-data.frame(cbind(rnorm(100,0,1),rnorm(100,0,1),rnorm(100,0,1),rnorm(100,0,1)))
Y<-as.matrix(Data) %*% as.matrix(c(1,2,-3,3)) + rnorm(100,0,2)
colnames(Data)<-c("PIB","RAE","LOA","WTC")
Data$Y <- Y
res<-glm(Y~.,data=Data)
summary(res)
glm_object<-glm(Y~.,data=Data)
table1<-data.frame(matrix(NA,length(glm_object$coefficients)-1,8))
rownames(table1)<-names(glm_object$coefficients)[2:length(glm_object$coefficients)]
table1
colnames(table1)<-c("exp MLE coeff","standard error delta","p-value Wald","p-value deviance","low.conf.inter. exp coeff Wald test","up.conf.inter. exp coeff Wald test","low.conf.inter. exp coeff being likelihood-ratio test","up.conf.inter. exp coeff being likelihood-ratio test")
table1
table1[,1]
glm_object$coefficients[2:length(glm_object$coefficients)]
exp(glm_object$coefficients[2:length(glm_object$coefficients)])
table1[,1]<-exp(glm_object$coefficients[2:length(glm_object$coefficients)])
table1
table1[,1]<-round(exp(glm_object$coefficients[2:length(glm_object$coefficients)]),3)
table1
fit_ordinalPO_mental<-glm(Y~.,data=Data)
coefficients(fit_ordinalPO_mental,matrix=TRUE)#Thisdoesnot
stdbeta_ses<-0.6143#Standarderrorforsesextractedfromoutput
ICORmin<-exp(coefficients(fit_ordinalPO_mental)["factor(ses)1"])*(1-stdbeta_ses*qnorm((1+0.95)/2,mean=0,sd=1))
ICORmax<-exp(coefficients(fit_ordinalPO_mental)["factor(ses)1"])*(1+stdbeta_ses*qnorm((1+0.95)/2,mean=0,sd=1))
print(c(ICORmin,ICORmax))#95%ACIforoddsratio,whichis
exp(beta)
coefficients(fit_ordinalPO_mental,matrix=TRUE)#Thisdoesnotgivestandarderrorsasinglm...
ICORmin<-exp(coefficients(fit_ordinalPO_mental)["PIB"])*(1-stdbeta_ses*qnorm((1+0.95)/2,mean=0,sd=1))
ICORmax<-exp(coefficients(fit_ordinalPO_mental)["PIB"])*(1+stdbeta_ses*qnorm((1+0.95)/2,mean=0,sd=1))
print(c(ICORmin,ICORmax))#95%ACIforoddsratio,whichis
exp(beta)
table1
exp(coefficients(fit_ordinalPO_mental)["PIB"])
stdbeta_ses
trump_model <- glm(Y~.,data=Data)
estimates <- round(coef(trump_model), 3)
estimates
results_tab <- tidy(trump_model) %>%
mutate_if(is.numeric, funs(round(.,3))) %>%
var_mapping(term) %>%
dplyr::rename(Estimate = term, Beta = estimate, SE = std.error, z = statistic, p = p.value)
kable(results_tab, align = c("l",rep("c",4)))
glm_object
glm_object$fitted.values
summary(glm_object)
summary(glm_object)[[2]]
summary(glm_object)[[2]]
summary(glm_object)[[3]]
summary(glm_object)[[4]]
summary(glm_object)[[5]]
summary(glm_object)[[1]]
summary(glm_object)[[2]]
summary(glm_object)$coefficiant
summary(glm_object)$Coefficients
summary(glm_object)$coefficients
summary(glm_object)$coefficients[,2]
table1[,2]<-round(sqrt(exp(glm_object$coefficients[2:length(glm_object$coefficients)]) *(summary(glm_object)$coefficients[,2][2:length(glm_object$coefficients)])^2 *exp(glm_object$coefficients[2:length(glm_object$coefficients)])),3)
table1
11000/25.78
11000/24.65
100 + 200
500/25
200*22
200*22,5
200*22.5
200*25
200*23
200*23
200*22
16.91 * 24.75
48 *4
#install.packages(pkgs="http://www.karlin.mff.cuni.cz/~hlavka/sms2/SMSdata_1.0.tar.gz", repos=NULL, type="source")
library(SMSdata)
data(food)
library("FactoMineR")
library("factoextra")
library("qgraph")
library(corrplot)
library(tidyverse)
#install.packages(pkgs="http://www.karlin.mff.cuni.cz/~hlavka/sms2/SMSdata_1.0.tar.gz", repos=NULL, type="source")
library(SMSdata)
data(food)
library("FactoMineR")
library("factoextra")
library("qgraph")
library(corrplot)
library(tidyverse)
food.fa <- factanal(food, factors = 2)
(food.fa <- factanal(food, factors = 2))
print(food.fa, digits=2, cutoff=.6, sort=TRUE)
library(nFactors)
install.packages("nFactors")
library(nFactors)
install.packages("nFactors")
install.packages("nFactors")
load <- fa1$loadings[,1:2]
load <- food.fa$loadings[,1:2]
plot(load,type="n")
text(load,labels=names(food),cex=.7)
lines(c(-1,1),c(0,0), lty = 3)
lines(c(0,0),c(-1,1), lty = 3)
rbPal <- colorRampPalette(c('red','blue'))
loadings <- data.frame(fa1$loadings[,1:3])
rbPal <- colorRampPalette(c('red','blue'))
loadings <- data.frame(food.fa$loadings[,1:3])
(food.fa$loadings[,1:3])
food.fa
food.fa$loadings
loadings <- data.frame(food.fa$loadings[,1:2])
loadings$colF1 <- rbPal(20)[as.numeric(cut(loadings[,1],breaks = seq(-1,1,length = 20)))]
loadings$nam1 <- paste(row.names(loadings), round(loadings[,1], digits = 3), sep = "\n")
loadings$colF2 <- rbPal(20)[as.numeric(cut(loadings[,2],breaks = seq(-1,1,length = 20)))]
loadings$nam2 <- paste(row.names(loadings), round(loadings[,2], digits = 3), sep = "\n")
loadings$colF3 <- rbPal(20)[as.numeric(cut(loadings[,3],breaks = seq(-1,1,length = 20)))]
loadings$nam3 <- paste(row.names(loadings), round(loadings[,3], digits = 3), sep = "\n")
rbPal <- colorRampPalette(c('red','blue'))
loadings <- data.frame(food.fa$loadings[,1:2])
loadings$colF1 <- rbPal(20)[as.numeric(cut(loadings[,1],breaks = seq(-1,1,length = 20)))]
loadings$nam1 <- paste(row.names(loadings), round(loadings[,1], digits = 3), sep = "\n")
loadings$colF2 <- rbPal(20)[as.numeric(cut(loadings[,2],breaks = seq(-1,1,length = 20)))]
loadings$nam2 <- paste(row.names(loadings), round(loadings[,2], digits = 3), sep = "\n")
par(mfrow = c(2,1))
barplot(abs(loadings[,1]), col = loadings$colF1, ylim = c(0,1), ylab = "Factor 1", names.arg = loadings$nam1, cex.names = 0.8)
barplot(abs(loadings[,2]), col = loadings$colF2, ylim = c(0,1), ylab = "Factor 2", names.arg = loadings$nam2, cex.names = 0.8)
install.packages("RcmdrMisc")
library(RcmdrMisc)
rcorr.adjust(food) # This function is build into R Commander.
## If you want to run this before eliminating missing values use:
# rcorr.adjust(mydata, use="pairwise.complete.obs")
write.csv(cor(food)>0.8, file="Suspect_Correlations.csv")
write.csv(cor(food), file="Correlation_Values.csv")
rcorr.adjust(food) # This function is build into R Commander.
library(psych)
library(psych)
KMO(mydata)
library(psych)
KMO(food)
View(food)
KMO(food)$MSA
fa.food <- factanal(food, factors = 3, rotation="varimax")
print(fa.food, digits=2, cutoff=.6, sort=TRUE)
install.packages("nFactors")
library(nFactors)
ev <- eigen(cor(food))
ap <- parallel(subject=nrow(food),var=ncol(food), rep=100, cent=.05)
nS <- nScree(x=ev$values, aparallel=ap$eigen$qevpea)
plotnScree(nS)
rbPal <- colorRampPalette(c('red','blue'))
loadings <- data.frame(food.fa$loadings[,1:2])
loadings$colF1 <- rbPal(20)[as.numeric(cut(loadings[,1],breaks = seq(-1,1,length = 20)))]
loadings$nam1 <- paste(row.names(loadings), round(loadings[,1], digits = 3), sep = "\n")
loadings$colF2 <- rbPal(20)[as.numeric(cut(loadings[,2],breaks = seq(-1,1,length = 20)))]
loadings$nam2 <- paste(row.names(loadings), round(loadings[,2], digits = 3), sep = "\n")
par(mfrow = c(2,1))
barplot(abs(loadings[,1]), col = loadings$colF1, ylim = c(0,1), ylab = "Factor 1", names.arg = loadings$nam1, cex.names = 0.8)
barplot(abs(loadings[,2]), col = loadings$colF2, ylim = c(0,1), ylab = "Factor 2", names.arg = loadings$nam2, cex.names = 0.8)
load <- food.fa$loadings[,1:2]
plot(load,type="n")
text(load,labels=names(food),cex=.7)
lines(c(-1,1),c(0,0), lty = 3)
lines(c(0,0),c(-1,1), lty = 3)
scree(food, pc=FALSE)  # Use pc=FALSE for factor analysis
round(483/8192*100,2)
483/8192*100
round(483/8192*100,2)
plot(ggeffect(regm3, "region"))
###intro###
#
library("colorspace")
library("xtable")
library(MASS)
library(questionr)
library(nnet)
library(broom.helpers)
#
setwd("C:/Users/guill/OneDrive/Documents/Charles_University/Advanced Regression Models/Work4")
print(load("AdvRegr_4_nels.RData"))
###part 1###
#socio-economic status of the family with the achieved level of education of the father.
#repartition %
round(prop.table(with(nels, table(fa.educ, useNA = "ifany")))*100,2)
### Contingency table
(tab1 <- with(nels, table(ses, fa.educ)))
(ptab1 <- round(prop.table(tab1, margin = 2) * 100, 1))
#First observation :
#Elementary -> more 1 & 2
#High -> More 2 & 3
#College -> More 4
### Data frame for loglinear modelling
(qq1 <- as.data.frame(tab1, responseName = "N"))
fit1 <- glm(N ~ ses + fa.educ + ses:fa.educ, family = poisson, data = qq1)
###part 2###
#socio-economic status of the family with the achieved level of education of the father.
#+region
#repartition %
round(prop.table(with(nels, table(region, useNA = "ifany")))*100,2)
#South is bigger
### Contingency table
(tab2 <- with(nels, table(ses, fa.educ,region)))
(ptab2 <- round(prop.table(tab2, margin = 2) * 100, 1))
### Data frame for loglinear modelling
(qq2 <- as.data.frame(tab2, responseName = "N"))
fitp2.1 <- glm(N ~ ses + fa.educ + region, family = poisson, data = qq2)
fitp2.2 <- glm(N ~ (ses:fa.educ)+(ses:region)+(fa.educ:region), family = poisson, data = qq2)
fitp2.3 <- glm(N ~ (ses:fa.educ:region), family = poisson, data = qq2)
summary(fitp2.1)
summary(fitp2.2)
summary(fitp2.3)
###part 3###
#socio-economic status of the family with the achieved level of education of the father.
#+region + fa.wrk
regm3 <- multinom(ses ~ fa.educ +region+fa.wrk ,family=poisson, data = nels)
summary(regm3)
odds.ratio(regm3)
ggcoef_multinom(
regm3,
exponentiate = TRUE
)
<<<<<<< HEAD
install.packages('GGally')
#
=======
library(ggeffects)
plot(ggeffect(regm3, "region"))
plot(ggeffect(regm3, "region"))
ggcoef_multinom(
regm3,
exponentiate = TRUE
)
library(GGally)
ggcoef_multinom(
regm3,
exponentiate = TRUE
)
### Data frame for loglinear modelling
fit1 <- glm(ses ~ fa.educ + fa.educ, family = poisson, data = qq1)
### Data frame for loglinear modelling
fit1 <- glm(ses ~ fa.educ , family = poisson, data = qq1)
View(qq1)
### Data frame for loglinear modelling
fit1 <- glm(ses ~ fa.educ , family = poisson, data = nels)
>>>>>>> 3491978b8b8b289a5b4ccd50416c38661c4c805a
library("colorspace")
library("xtable")
library(MASS)
library(questionr)
library(nnet)
library(broom.helpers)
<<<<<<< HEAD
=======
library(GGally)
#
setwd("C:/Users/guill/OneDrive/Documents/Charles_University/Advanced Regression Models/Work4")
>>>>>>> 3491978b8b8b289a5b4ccd50416c38661c4c805a
print(load("AdvRegr_4_nels.RData"))
#repartition %
round(prop.table(with(nels, table(fa.educ, useNA = "ifany")))*100,2)
### Contingency table
(tab1 <- with(nels, table(ses, fa.educ)))
(ptab1 <- round(prop.table(tab1, margin = 2) * 100, 1))
### Data frame for loglinear modelling
<<<<<<< HEAD
(qq1 <- as.data.frame(tab1, responseName = "N"))
#
#setwd("C:/Users/guill/OneDrive/Documents/Charles_University/Advanced Regression Models/Work4")
rm(list=ls())
print(load("AdvRegr_4_nels.RData"))
#repartition %
round(prop.table(with(nels, table(fa.educ, useNA = "ifany")))*100,2)
### Contingency table
(tab1 <- with(nels, table(ses, fa.educ)))
(ptab1 <- round(prop.table(tab1, margin = 2) * 100, 1))
### Data frame for loglinear modelling
fit1 <- glm(ses~fa.educ, family = poisson, data = nels)
summary(fit1)
View(nels)
#First observation :
#Elementary -> more 1 & 2
#High -> More 2 & 3
#College -> More 4
sum(is.na(nels$fa.educ))
#First observation :
#Elementary -> more 1 & 2
#High -> More 2 & 3
#College -> More 4
sum(is.na(nels$ses))
is.na(nels$ses)
### Data frame for loglinear modelling
fit1 <- glm(ses~fa.educ, family = poisson, data = nels)
summary(fit1)
(qq1 <- as.data.frame(tab1, responseName = "N"))
fit1 <- glm(N ~ ses + fa.educ + ses:fa.educ, family = poisson, data = qq1)
summary(fit1)
### Data frame for loglinear modelling
fit1 <- glm(ses~fa.educ, family = poisson, data = nels)
fit2 = glm(ses~fa.educ+region, family = poisson, data=nels)
regm3 <- multinom(ses ~ fa.educ +region+fa.wrk ,family=poisson, data = nels)
#
library("colorspace")
library("xtable")
#
rm(list=ls())
print(load("AdvRegr_4_nels.RData"))
### Marginal frequencies
with(nels, table(ses,     useNA = "ifany"))
with(nels, table(sesmed,  useNA = "ifany"))
with(nels, table(parents, useNA = "ifany"))
with(nels, table(foreign, useNA = "ifany"))
with(nels, table(fa.educ, useNA = "ifany"))
with(nels, table(mo.educ, useNA = "ifany"))
with(nels, table(region,  useNA = "ifany"))
with(nels, table(fa.wrk,  useNA = "ifany"))
with(nels, table(mo.wrk,  useNA = "ifany"))
### Contingency table
(xtab1 <- with(nels, table(ses, fa.educ)))
### Exploration: column proportions
prop.table(xtab1, margin = 2)
### Formatted numbers
(ptab1 <- round(prop.table(xtab1, margin = 2) * 100, 1))
### Table in LaTeX
print(xtable(ptab1, digits = c(0, 1, 1, 1)), floating = FALSE)
### Plot (two slightly different versions)
par(mfrow = c(1, 2), mar = c(3, 3, 3, 1) + 0.1)
plot(t(xtab1), col = rainbow_hcl(4), main = "SES by father's education")
plot(ses ~ fa.educ, data = nels, col = rainbow_hcl(4),
main = "SES by father's education")
par(mfrow = c(1, 1))
### Chi^2 test
chisq.test(xtab1)
### Data frame for loglinear modelling
(qq1 <- as.data.frame(xtab1, responseName = "N"))
### Saturated model
fit1 <- glm(N ~ (ses + fa.educ)^2, family = poisson, data = qq1)
fit1 <- glm(N ~ ses + fa.educ + ses:fa.educ, family = poisson, data = qq1)
## the same as above
summary(fit1)         ### Surprised by (numerically) zero residual deviance?
### Independence model
fit0 <- glm(N ~ ses + fa.educ, family = poisson, data = qq1)
summary(fit0)
### Deviance (likelihood-ratio) test of independence
anova(fit0, fit1, test = "LRT")
fit1 <- glm(N ~ ses + fa.educ + ses:fa.educ, family = poisson, data = qq1)
## the same as above
summary(fit1)         ### Surprised by (numerically) zero residual deviance?
### Independence model
fit0 <- glm(N ~ ses + fa.educ, family = poisson, data = qq1)
summary(fit0)
### Deviance (likelihood-ratio) test of independence
anova(fit0, fit1, test = "LRT")
### Score test of independence
chisq.test(xtab1)
### Yes, the classical chi-sq test of independence
### is the score test in the corresponding loglinear model
anova(fit0, fit1, test = "Rao")
### Also the Wald test can be considered
(be1 <- coef(fit1))
V1 <- vcov(fit1)
(interIndex <- grep(":fa.educ", names(be1)))
W <- as.numeric(be1[interIndex] %*% solve(V1[interIndex, interIndex], be1[interIndex]))
pW <- pchisq(W, df = length(interIndex), lower.tail = FALSE)
Wald  <- data.frame(W = W, df = length(interIndex), Pvalue = pW)
print(Wald)
### Coef interpretation
exp(coef(fit1)[-1])
round(exp(coef(fit1)[-1]), 2)    ### Meaning of each coefficient?
### Check levels of the two factors
with(nels, table(ses,     useNA = "ifany"))
with(nels, table(fa.educ, useNA = "ifany"))
contr.treatment(3)
### ODDS on better ses (compared to ses = 1)
### given father's education
### ----------------------------------------
#
### fa.educ = Elementary
be1[paste("ses", 2:4, sep = "")]
(oddsElem <- exp(be1[paste("ses", 2:4, sep = "")]))
#
### fa.educ = High
be1[paste("ses", 2:4, sep = "")]
be1[paste("ses", 2:4, ":fa.educHigh", sep = "")]
(oddsHigh <- exp(be1[paste("ses", 2:4, sep = "")] +
be1[paste("ses", 2:4, ":fa.educHigh", sep = "")]))
#
### fa.educ = College
be1[paste("ses", 2:4, sep = "")]
be1[paste("ses", 2:4, ":fa.educCollege", sep = "")]
(oddsColl <- exp(be1[paste("ses", 2:4, sep = "")] +
be1[paste("ses", 2:4, ":fa.educCollege", sep = "")]))
### All in one table
ODDSbetterSES <- data.frame(Elementary = oddsElem, High = oddsHigh,
College = oddsColl)
print(ODDSbetterSES)
### ODDS on better education (compared to fa.educ = Elementary)
### given family SES
### -----------------------------------------------------------------------
#
### ses = 1
(odds1 <- exp(be1[paste("fa.educ", c("High", "College"), sep = "")]))
#
### ses = 2
(odds2 <- exp(be1[paste("fa.educ", c("High", "College"), sep = "")] +
be1[paste("ses2:fa.educ", c("High", "College"), sep = "")]))
#
### ses = 3
(odds3 <- exp(be1[paste("fa.educ", c("High", "College"), sep = "")] +
be1[paste("ses3:fa.educ", c("High", "College"), sep = "")]))
#
### ses = 4
(odds4 <- exp(be1[paste("fa.educ", c("High", "College"), sep = "")] +
be1[paste("ses4:fa.educ", c("High", "College"), sep = "")]))
### All in one table
ODDShigherEduc <- data.frame(ses1 = odds1, ses2 = odds2, ses3 = odds3, ses4 = odds4)
print(ODDShigherEduc)
### ODDS RATIOS (ratios of odds on higher ses compared to ses = 1
###   when comparing higher levels of education with Elementary one)
###
### = ODDS RATIOS (ratios of odds on higher level of education
###   compared to Elementary one)
###   when comparing higher ses with ses = 1)
###
### -----------------------------------------------------------------------------
exp(be1[grep(":fa.educ", names(be1))])
### ODDS RATIOS (ratios of odds on higher ses compared to ses = 1
###   when comparing College education with High education)
###
### = ODDS RATIOS (ratios of odds on College education compared to High education
###   when comparing higher ses with ses = 1
### ------------------------------------------------------------------------------
exp(be1[grep(":fa.educCollege", names(be1))] - be1[grep(":fa.educHigh", names(be1))])
### Are fit0 and fit1 the only reasonable models in this situation?
###
### How about the model below?
### Does it have reasonable interpretation?
### ----------------------------------------------------------------------
qq1 <- transform(qq1, nses = as.numeric(ses))
print(qq1)
summary(qq1)
### Linear trend?
fit1n <- glm(N ~ (nses + fa.educ)^2, family = poisson, data = qq1)
View(qq1)
summary(fit1n)
be1n <- coef(fit1n)
### Odds on better ses (by 1)
### ----------------------------------------
#
### fa.educ = Elementary
exp(be1n["nses"])
#
(oddsnElem <- exp(be1n["nses"] * 1:3))  ## trend
exp(be1[paste("ses", 2:4, sep = "")])   ## saturated
#
### fa.educ = High
exp(be1n["nses"] + be1n["nses:fa.educHigh"])
#
(oddsnHigh <- exp((be1n["nses"] + be1n["nses:fa.educHigh"]) * 1:3))  ## trend
exp(be1[paste("ses", 2:4, sep = "")] +                           ## saturated
be1[paste("ses", 2:4, ":fa.educHigh", sep = "")])
#
### fa.educ = College
exp(be1n["nses"] + be1n["nses:fa.educCollege"])
#
(oddsnColl <- exp((be1n["nses"] + be1n["nses:fa.educCollege"]) * 1:3)) ## trend
exp(be1[paste("ses", 2:4, sep = "")] +                             ## saturated
be1[paste("ses", 2:4, ":fa.educCollege", sep = "")])
### All in one table
ODDSnbetterSES <- data.frame(Elementary = oddsnElem, High = oddsnHigh,
College = oddsnColl)
#
### Compare
print(ODDSnbetterSES)          ## SES ordinal (numeric)
print(ODDSbetterSES)           ## SES nominal
### Is (saturated) fit1 significantly better than fit1n?
### -------------------------------------------------------
anova(fit1n, fit1, test = "LRT")
### Odds on better education (compared to fa.educ = Elementary)
### -----------------------------------------------------------------------
#
### ses = 1
(oddsn1 <- exp(be1n[paste("fa.educ", c("High", "College"), sep = "")] +
be1n[paste("nses:fa.educ", c("High", "College"), sep = "")]))
#
exp(be1[paste("fa.educ", c("High", "College"), sep = "")])   ## Compare (saturated)
#
### ses = 2
(oddsn2 <- exp(be1n[paste("fa.educ", c("High", "College"), sep = "")] +
2 * be1n[paste("nses:fa.educ", c("High", "College"), sep = "")]))
#
exp(be1[paste("fa.educ", c("High", "College"), sep = "")] +
be1[paste("ses2:fa.educ", c("High", "College"), sep = "")])
#
### ses = 3
(oddsn3 <- exp(be1n[paste("fa.educ", c("High", "College"), sep = "")] +
3 * be1n[paste("nses:fa.educ", c("High", "College"), sep = "")]))
#
exp(be1[paste("fa.educ", c("High", "College"), sep = "")] +
be1[paste("ses3:fa.educ", c("High", "College"), sep = "")])
#
### ses = 4
(oddsn4 <- exp(be1n[paste("fa.educ", c("High", "College"), sep = "")] +
4 * be1n[paste("nses:fa.educ", c("High", "College"), sep = "")]))
#
exp(be1[paste("fa.educ", c("High", "College"), sep = "")] +
be1[paste("ses4:fa.educ", c("High", "College"), sep = "")])
### All in one table
ODDSnhigherEduc <- data.frame(ses1 = oddsn1, ses2 = oddsn2, ses3 = oddsn3,
ses4 = oddsn4)
#
### Compare
print(ODDSnhigherEduc)          ## SES ordinal (numeric)
print(ODDShigherEduc)           ## SES nominal
##### (Useful?) function to calculate
##### a goodness-of-fit test
##### - perhaps useful for multi-dimensional tables
##### ==============================================
gof <- function(m){
DD <- deviance(m)
df <- m$df.residual
pval <- pchisq(DD, df, lower.tail = FALSE)
nparm <- length(coef(m))
LowCount <- sum(fitted(m) <= 5)
cat("Goodness-of-fit test, model with ", nparm, " parameters\n", sep = "")
cat("Deviance = ", DD, ", df = ", df, "\n", sep = "")
cat("P-value: ", ifelse(pval < 0.001, "<0.001", format(round(pval, 3), nsmall = 3)), "\n\n", sep = "")
if (LowCount){
cat("Number of cells with low fitted counts: ", LowCount, "\n\n")
print(summary(fitted(m)))
}
}
gof(fit1n)  ## Test of a linear trend for X again
#
gof(fit1)      ### Hmmmm...
### Do you have a better name for chi^2 distribution
### with 0 degrees of freedom?
### Correct p-value:
pchisq(0, df = 0, lower.tail = FALSE)
#
gof(fit0)    ## Test of independence again
#
gof(fit0)    ## Test of independence again
=======
fit1 <- glm(ses ~ fa.educ , family = poisson, data = nels)
chisq.test(tab1)
mosaicplot(tab1, main = "Countries Mosaic Plot",
sub = "Product Colors by Country",
xlab = "Colors",
ylab = "Countries",
las = 1,
border = "chocolate",
shade = TRUE)
mosaicplot(tab1, main = "Countries Mosaic Plot",
sub = "Product Colors by Country",
xlab = "Colors",
ylab = "Father Education",
las = 1,
border = "chocolate",
shade = TRUE)
mosaicplot(tab1, main = "Countries Mosaic Plot",
sub = "Product Colors by Country",
xlab = "Socioeconomic status",
ylab = "Father Education",
las = 1,
border = "chocolate",
shade = TRUE)
mosaicplot(tab1, main = "Mosaic Plot",
xlab = "Socioeconomic status",
ylab = "Father Education",
las = 1,
border = "chocolate",
shade = TRUE)
mosaicplot(tab1, main = "Mosaic Plot",
xlab = "Socioeconomic status",
ylab = "Father Education",
las = 1,
border = "yellow",
shade = TRUE)
>>>>>>> 3491978b8b8b289a5b4ccd50416c38661c4c805a
